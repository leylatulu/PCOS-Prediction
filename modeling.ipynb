{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve, auc, f1_score, jaccard_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../SistersLab-Project/PCOS_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.drop([\"Sl. No\", \"Patient File No.\",  \"Unnamed: 44\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Height(Cm) ': 'Height(Cm)'}, inplace=True)\n",
    "df.rename(columns={'Marraige Status (Yrs)': 'Marriage Status (Yrs)'}, inplace=True)\n",
    "df.rename(columns={'Pulse rate(bpm) ': 'Pulse rate(bpm)'}, inplace=True)\n",
    "df.rename(columns={'II    beta-HCG(mIU/mL)': 'II_beta_HCG(mIU/mL)'}, inplace=True)\n",
    "df.rename(columns={' Age (yrs)': 'Age (yrs)'}, inplace=True)\n",
    "df.rename(columns={'  I   beta-HCG(mIU/mL)': 'I_beta_HCG(mIU/mL)'}, inplace=True)\n",
    "df.rename(columns={'No. of abortions': 'No_of_abortions'}, inplace=True)\n",
    "df.rename(columns={'BP _Systolic (mmHg)': 'BP_Systolic(mmHg)'}, inplace=True)\n",
    "df.rename(columns={'BP _Diastolic (mmHg)': 'BP_Diastolic(mmHg)'}, inplace=True)\n",
    "df.rename(columns={'Waist:Hip Ratio': 'WaistHip_Ratio'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['II_beta_HCG(mIU/mL)'] == '1.99.', 'II_beta_HCG(mIU/mL)'] = 1.99\n",
    "df.loc[df['AMH(ng/mL)'] == 'a', 'AMH(ng/mL)'] = np.nan # eksik değer\n",
    "df['II_beta_HCG(mIU/mL)'] = pd.to_numeric(df['II_beta_HCG(mIU/mL)'], errors='coerce').astype('float64')\n",
    "df['AMH(ng/mL)'] = pd.to_numeric(df['AMH(ng/mL)'], errors='coerce').astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.index == 329]\n",
    "df.drop(329, inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCOS (Y/N)               0\n",
       "Age (yrs)                0\n",
       "Weight (Kg)              0\n",
       "Height(Cm)               0\n",
       "BMI                      0\n",
       "Blood Group              0\n",
       "Pulse rate(bpm)          0\n",
       "RR (breaths/min)         0\n",
       "Hb(g/dl)                 0\n",
       "Cycle(R/I)               0\n",
       "Cycle length(days)       0\n",
       "Marriage Status (Yrs)    1\n",
       "Pregnant(Y/N)            0\n",
       "No_of_abortions          0\n",
       "I_beta_HCG(mIU/mL)       0\n",
       "II_beta_HCG(mIU/mL)      0\n",
       "FSH(mIU/mL)              0\n",
       "LH(mIU/mL)               0\n",
       "FSH/LH                   0\n",
       "Hip(inch)                0\n",
       "Waist(inch)              0\n",
       "WaistHip_Ratio           0\n",
       "TSH (mIU/L)              0\n",
       "AMH(ng/mL)               1\n",
       "PRL(ng/mL)               0\n",
       "Vit D3 (ng/mL)           0\n",
       "PRG(ng/mL)               0\n",
       "RBS(mg/dl)               0\n",
       "Weight gain(Y/N)         0\n",
       "hair growth(Y/N)         0\n",
       "Skin darkening (Y/N)     0\n",
       "Hair loss(Y/N)           0\n",
       "Pimples(Y/N)             0\n",
       "Fast food (Y/N)          1\n",
       "Reg.Exercise(Y/N)        0\n",
       "BP_Systolic(mmHg)        0\n",
       "BP_Diastolic(mmHg)       0\n",
       "Follicle No. (L)         0\n",
       "Follicle No. (R)         0\n",
       "Avg. F size (L) (mm)     0\n",
       "Avg. F size (R) (mm)     0\n",
       "Endometrium (mm)         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Marriage Status (Yrs)\"].fillna(df[\"Marriage Status (Yrs)\"].median(), inplace=True)\n",
    "df[\"AMH(ng/mL)\"].fillna(df[\"AMH(ng/mL)\"].median(), inplace=True)\n",
    "df[\"Fast food (Y/N)\"].fillna(df[\"Fast food (Y/N)\"].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['I_beta_HCG(mIU/mL)', 'II_beta_HCG(mIU/mL)'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[[\"PCOS (Y/N)\"]]\n",
    "X = df.drop(\"PCOS (Y/N)\", axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age (yrs)', 'Weight (Kg)', 'Height(Cm)', 'BMI', 'Blood Group',\n",
       "       'Pulse rate(bpm)', 'RR (breaths/min)', 'Hb(g/dl)', 'Cycle(R/I)',\n",
       "       'Cycle length(days)', 'Marriage Status (Yrs)', 'Pregnant(Y/N)',\n",
       "       'No_of_abortions', 'FSH(mIU/mL)', 'LH(mIU/mL)', 'FSH/LH', 'Hip(inch)',\n",
       "       'Waist(inch)', 'WaistHip_Ratio', 'TSH (mIU/L)', 'AMH(ng/mL)',\n",
       "       'PRL(ng/mL)', 'Vit D3 (ng/mL)', 'PRG(ng/mL)', 'RBS(mg/dl)',\n",
       "       'Weight gain(Y/N)', 'hair growth(Y/N)', 'Skin darkening (Y/N)',\n",
       "       'Hair loss(Y/N)', 'Pimples(Y/N)', 'Fast food (Y/N)',\n",
       "       'Reg.Exercise(Y/N)', 'BP_Systolic(mmHg)', 'BP_Diastolic(mmHg)',\n",
       "       'Follicle No. (L)', 'Follicle No. (R)', 'Avg. F size (L) (mm)',\n",
       "       'Avg. F size (R) (mm)', 'Endometrium (mm)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Age (yrs)', 'Weight (Kg)', 'Height(Cm)', 'BMI', 'Blood Group',\n",
    "       'Pulse rate(bpm)', 'RR (breaths/min)', 'Hb(g/dl)', 'Cycle(R/I)',\n",
    "       'Cycle length(days)', 'Marriage Status (Yrs)', 'Pregnant(Y/N)',\n",
    "       'No_of_abortions', #\n",
    "       'FSH(mIU/mL)', 'LH(mIU/mL)', 'FSH/LH', 'Hip(inch)', 'Waist(inch)',\n",
    "       'WaistHip_Ratio', 'TSH (mIU/L)', 'AMH(ng/mL)', 'PRL(ng/mL)',\n",
    "       'Vit D3 (ng/mL)', 'PRG(ng/mL)', 'RBS(mg/dl)', 'Weight gain(Y/N)',\n",
    "       'hair growth(Y/N)', 'Skin darkening (Y/N)', 'Hair loss(Y/N)',\n",
    "       'Pimples(Y/N)', 'Fast food (Y/N)', 'Reg.Exercise(Y/N)',\n",
    "       'BP_Systolic(mmHg)', 'BP_Diastolic(mmHg)', 'Follicle No. (L)',\n",
    "       'Follicle No. (R)', 'Avg. F size (L) (mm)', 'Avg. F size (R) (mm)',\n",
    "       'Endometrium (mm)']\n",
    "\n",
    "sc = StandardScaler()\n",
    "for col in cols:\n",
    "    X_train[col] = sc.fit_transform(X_train[[col]])\n",
    "    X_test[col] = sc.transform(X_test[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8703703703703703\n",
      "F1-score: 0.8720481044424706\n",
      "Jaccard score: 0.6818181818181818\n",
      "AUC score: 0.8669275929549902\n",
      "Confusion matrix: \n",
      " [[64  9]\n",
      " [ 5 30]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90        73\n",
      "           1       0.77      0.86      0.81        35\n",
      "\n",
      "    accuracy                           0.87       108\n",
      "   macro avg       0.85      0.87      0.86       108\n",
      "weighted avg       0.88      0.87      0.87       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train,y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred, average='weighted')) \n",
    "print(\"Jaccard score:\", jaccard_score(y_test, y_pred))\n",
    "print(\"AUC score:\", roc_auc_score(y_test, y_pred))\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9351851851851852\n",
      "F1-score: 0.9337654006528178\n",
      "Jaccard score: 0.8055555555555556\n",
      "AUC score: 0.9074363992172212\n",
      "Confusion matrix: \n",
      " [[72  1]\n",
      " [ 6 29]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        73\n",
      "           1       0.97      0.83      0.89        35\n",
      "\n",
      "    accuracy                           0.94       108\n",
      "   macro avg       0.94      0.91      0.92       108\n",
      "weighted avg       0.94      0.94      0.93       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = LogisticRegression(random_state=42)\n",
    "dt.fit(X_train,y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred, average='weighted')) \n",
    "print(\"Jaccard score:\", jaccard_score(y_test, y_pred))\n",
    "print(\"AUC score:\", roc_auc_score(y_test, y_pred))\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9259259259259259\n",
      "F1-score: 0.9239156920077972\n",
      "Jaccard score: 0.7777777777777778\n",
      "AUC score: 0.8931506849315068\n",
      "Confusion matrix: \n",
      " [[72  1]\n",
      " [ 7 28]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95        73\n",
      "           1       0.97      0.80      0.88        35\n",
      "\n",
      "    accuracy                           0.93       108\n",
      "   macro avg       0.94      0.89      0.91       108\n",
      "weighted avg       0.93      0.93      0.92       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = SVC(random_state=42)\n",
    "dt.fit(X_train,y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred, average='weighted')) \n",
    "print(\"Jaccard score:\", jaccard_score(y_test, y_pred))\n",
    "print(\"AUC score:\", roc_auc_score(y_test, y_pred))\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 142, number of negative: 290\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1570\n",
      "[LightGBM] [Info] Number of data points in the train set: 432, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.328704 -> initscore=-0.714054\n",
      "[LightGBM] [Info] Start training from score -0.714054\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy: 0.9629629629629629\n",
      "F1-score: 0.962334455667789\n",
      "Jaccard score: 0.8857142857142857\n",
      "AUC score: 0.9428571428571428\n",
      "Confusion matrix: [[73  0]\n",
      " [ 4 31]]\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97        73\n",
      "           1       1.00      0.89      0.94        35\n",
      "\n",
      "    accuracy                           0.96       108\n",
      "   macro avg       0.97      0.94      0.96       108\n",
      "weighted avg       0.96      0.96      0.96       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = LGBMClassifier(random_state=42)\n",
    "dt.fit(X_train,y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred, average='weighted')) \n",
    "print(\"Jaccard score:\", jaccard_score(y_test, y_pred))\n",
    "print(\"AUC score:\", roc_auc_score(y_test, y_pred))\n",
    "print(\"Confusion matrix:\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9629629629629629\n",
      "F1-score: 0.9626685509038451\n",
      "Jaccard score: 0.8888888888888888\n",
      "AUC score: 0.9502935420743639\n",
      "Confusion matrix: \n",
      " [[72  1]\n",
      " [ 3 32]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97        73\n",
      "           1       0.97      0.91      0.94        35\n",
      "\n",
      "    accuracy                           0.96       108\n",
      "   macro avg       0.96      0.95      0.96       108\n",
      "weighted avg       0.96      0.96      0.96       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = XGBClassifier(random_state=42)\n",
    "dt.fit(X_train,y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred, average='weighted')) \n",
    "print(\"Jaccard score:\", jaccard_score(y_test, y_pred))\n",
    "print(\"AUC score:\", roc_auc_score(y_test, y_pred))\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 142, number of negative: 290\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1723\n",
      "[LightGBM] [Info] Number of data points in the train set: 432, number of used features: 41\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.328704 -> initscore=-0.714054\n",
      "[LightGBM] [Info] Start training from score -0.714054\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "# Modellerin ve metriklerin isimleri\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'SVC': SVC(),\n",
    "    'DecisionTree': DecisionTreeClassifier(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    'LightGBM': LGBMClassifier()\n",
    "}\n",
    "\n",
    "metrics = ['accuracy', 'f1', 'jaccard', 'auc']\n",
    "\n",
    "results_list = []\n",
    "\n",
    "# Her modeli eğit ve metrikleri hesapla\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    jaccard = jaccard_score(y_test, y_pred)\n",
    "    \n",
    "    # AUC score sadece binary sınıflandırma modelleri içindir, bu nedenle kontrol yapalım\n",
    "    if isinstance(model, (LogisticRegression, SVC, DecisionTreeClassifier, XGBClassifier, LGBMClassifier)):\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "    else:\n",
    "        auc = None\n",
    "    \n",
    "    # Liste üzerinde tuple olarak sonuçları ekleyin\n",
    "    results_list.append((model_name, accuracy, f1, jaccard, auc))\n",
    "\n",
    "# Listeyi kullanarak sonuçları DataFrame'e çevir\n",
    "results_df = pd.DataFrame(results_list, columns=['Model', 'Accuracy', 'F1 Score', 'Jaccard Score', 'AUC Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Jaccard Score</th>\n",
       "      <th>AUC Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.935185</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.907436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.893151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.867515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.950294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.942857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Accuracy  F1 Score  Jaccard Score  AUC Score\n",
       "0  LogisticRegression  0.935185  0.892308       0.805556   0.907436\n",
       "1                 SVC  0.925926  0.875000       0.777778   0.893151\n",
       "2        DecisionTree  0.861111  0.805195       0.673913   0.867515\n",
       "3             XGBoost  0.962963  0.941176       0.888889   0.950294\n",
       "4            LightGBM  0.962963  0.939394       0.885714   0.942857"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "index =[\"non PCOS\", \"PCOS\"]\n",
    "columns=[\"non PCOS\",\"PCOS\"]\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), index=index, columns=columns)\n",
    "sns.heatmap(cm, annot=True, fmt='d', annot_kws={'size': 15, 'fontweight': 'semibold'})\n",
    "plt.xlabel(\"Predicted value\")\n",
    "plt.ylabel(\"Actual value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.title('ROC eğrisi')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('Doğru Pozitif Oranı')\n",
    "plt.xlabel('Yanlış Pozitif Oranı')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parameters = {'criterion':['gini','entropy'],'max_depth':[2,5,10,20,30,90],'random_state':[42,34,2]}\n",
    "grid = GridSearchCV(DecisionTreeClassifier(), parameters, cv=10)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "best_parameters=grid.best_params_\n",
    "\n",
    "print(\"en iyi parametreler: \\n\",best_parameters)\n",
    "\n",
    "grid_model = DecisionTreeClassifier(criterion=best_parameters[\"criterion\"],\n",
    "                               max_depth=best_parameters[\"max_depth\"])\n",
    "\n",
    "tuned_model = grid_model.fit(X_train, y_train)\n",
    "y_pred = tuned_model.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Modelleri ve hiperparametre uzayını tanımlayın\n",
    "models = {\n",
    "    'LogisticRegression': (LogisticRegression(), {'C': [0.001, 0.01, 0.1, 1, 10, 100]}),\n",
    "    'SVC': (SVC(), {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'kernel': ['linear', 'rbf']}),\n",
    "    'DecisionTree': (DecisionTreeClassifier(), {'max_depth': [None, 10, 20, 30, 40]}),\n",
    "    'XGBoost': (XGBClassifier(), {'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3], 'n_estimators': [50, 100, 200, 300]}),\n",
    "    'LightGBM': (LGBMClassifier(), {'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3], 'n_estimators': [50, 100, 200, 300]})\n",
    "}\n",
    "\n",
    "# Her model için GridSearchCV uygula\n",
    "for model_name, (model, param_grid) in models.items():\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # En iyi hiperparametreleri ve doğruluk skorunu yazdır\n",
    "    print(f\"Best parameters for {model_name}: {grid_search.best_params_}\")\n",
    "    print(f\"Best accuracy score for {model_name}: {grid_search.best_score_}\")\n",
    "\n",
    "    # Test seti üzerinde performansı değerlendir\n",
    "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test accuracy score for {model_name}: {accuracy}\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

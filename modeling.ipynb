{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve, auc, f1_score, jaccard_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../SistersLab-Project/PCOS_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.drop([\"Sl. No\", \"Patient File No.\",  \"Unnamed: 44\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Height(Cm) ': 'Height(Cm)'}, inplace=True)\n",
    "df.rename(columns={'Marraige Status (Yrs)': 'Marriage Status (Yrs)'}, inplace=True)\n",
    "df.rename(columns={'Pulse rate(bpm) ': 'Pulse rate(bpm)'}, inplace=True)\n",
    "df.rename(columns={'II    beta-HCG(mIU/mL)': 'II_beta_HCG(mIU/mL)'}, inplace=True)\n",
    "df.rename(columns={' Age (yrs)': 'Age (yrs)'}, inplace=True)\n",
    "df.rename(columns={'  I   beta-HCG(mIU/mL)': 'I_beta_HCG(mIU/mL)'}, inplace=True)\n",
    "df.rename(columns={'No. of abortions': 'No_of_abortions'}, inplace=True)\n",
    "df.rename(columns={'BP _Systolic (mmHg)': 'BP_Systolic(mmHg)'}, inplace=True)\n",
    "df.rename(columns={'BP _Diastolic (mmHg)': 'BP_Diastolic(mmHg)'}, inplace=True)\n",
    "df.rename(columns={'Waist:Hip Ratio': 'WaistHip_Ratio'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['II_beta_HCG(mIU/mL)'] == '1.99.', 'II_beta_HCG(mIU/mL)'] = 1.99\n",
    "df.loc[df['AMH(ng/mL)'] == 'a', 'AMH(ng/mL)'] = np.nan # eksik deÄŸer\n",
    "df['II_beta_HCG(mIU/mL)'] = pd.to_numeric(df['II_beta_HCG(mIU/mL)'], errors='coerce').astype('float64')\n",
    "df['AMH(ng/mL)'] = pd.to_numeric(df['AMH(ng/mL)'], errors='coerce').astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.index == 329]\n",
    "df.drop(329, inplace=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCOS (Y/N)               0\n",
       "Age (yrs)                0\n",
       "Weight (Kg)              0\n",
       "Height(Cm)               0\n",
       "BMI                      0\n",
       "Blood Group              0\n",
       "Pulse rate(bpm)          0\n",
       "RR (breaths/min)         0\n",
       "Hb(g/dl)                 0\n",
       "Cycle(R/I)               0\n",
       "Cycle length(days)       0\n",
       "Marriage Status (Yrs)    1\n",
       "Pregnant(Y/N)            0\n",
       "No_of_abortions          0\n",
       "I_beta_HCG(mIU/mL)       0\n",
       "II_beta_HCG(mIU/mL)      0\n",
       "FSH(mIU/mL)              0\n",
       "LH(mIU/mL)               0\n",
       "FSH/LH                   0\n",
       "Hip(inch)                0\n",
       "Waist(inch)              0\n",
       "WaistHip_Ratio           0\n",
       "TSH (mIU/L)              0\n",
       "AMH(ng/mL)               1\n",
       "PRL(ng/mL)               0\n",
       "Vit D3 (ng/mL)           0\n",
       "PRG(ng/mL)               0\n",
       "RBS(mg/dl)               0\n",
       "Weight gain(Y/N)         0\n",
       "hair growth(Y/N)         0\n",
       "Skin darkening (Y/N)     0\n",
       "Hair loss(Y/N)           0\n",
       "Pimples(Y/N)             0\n",
       "Fast food (Y/N)          1\n",
       "Reg.Exercise(Y/N)        0\n",
       "BP_Systolic(mmHg)        0\n",
       "BP_Diastolic(mmHg)       0\n",
       "Follicle No. (L)         0\n",
       "Follicle No. (R)         0\n",
       "Avg. F size (L) (mm)     0\n",
       "Avg. F size (R) (mm)     0\n",
       "Endometrium (mm)         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Marriage Status (Yrs)\"].fillna(df[\"Marriage Status (Yrs)\"].median(), inplace=True)\n",
    "df[\"AMH(ng/mL)\"].fillna(df[\"AMH(ng/mL)\"].median(), inplace=True)\n",
    "df[\"Fast food (Y/N)\"].fillna(df[\"Fast food (Y/N)\"].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['I_beta_HCG(mIU/mL)', 'II_beta_HCG(mIU/mL)'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[[\"PCOS (Y/N)\"]]\n",
    "X = df.drop(\"PCOS (Y/N)\", axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age (yrs)', 'Weight (Kg)', 'Height(Cm)', 'BMI', 'Blood Group',\n",
       "       'Pulse rate(bpm)', 'RR (breaths/min)', 'Hb(g/dl)', 'Cycle(R/I)',\n",
       "       'Cycle length(days)', 'Marriage Status (Yrs)', 'Pregnant(Y/N)',\n",
       "       'No_of_abortions', 'FSH(mIU/mL)', 'LH(mIU/mL)', 'FSH/LH', 'Hip(inch)',\n",
       "       'Waist(inch)', 'WaistHip_Ratio', 'TSH (mIU/L)', 'AMH(ng/mL)',\n",
       "       'PRL(ng/mL)', 'Vit D3 (ng/mL)', 'PRG(ng/mL)', 'RBS(mg/dl)',\n",
       "       'Weight gain(Y/N)', 'hair growth(Y/N)', 'Skin darkening (Y/N)',\n",
       "       'Hair loss(Y/N)', 'Pimples(Y/N)', 'Fast food (Y/N)',\n",
       "       'Reg.Exercise(Y/N)', 'BP_Systolic(mmHg)', 'BP_Diastolic(mmHg)',\n",
       "       'Follicle No. (L)', 'Follicle No. (R)', 'Avg. F size (L) (mm)',\n",
       "       'Avg. F size (R) (mm)', 'Endometrium (mm)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Age (yrs)', 'Weight (Kg)', 'Height(Cm)', 'BMI', 'Blood Group',\n",
    "       'Pulse rate(bpm)', 'RR (breaths/min)', 'Hb(g/dl)', 'Cycle(R/I)',\n",
    "       'Cycle length(days)', 'Marriage Status (Yrs)', 'Pregnant(Y/N)',\n",
    "       'No_of_abortions', #\n",
    "       'FSH(mIU/mL)', 'LH(mIU/mL)', 'FSH/LH', 'Hip(inch)', 'Waist(inch)',\n",
    "       'WaistHip_Ratio', 'TSH (mIU/L)', 'AMH(ng/mL)', 'PRL(ng/mL)',\n",
    "       'Vit D3 (ng/mL)', 'PRG(ng/mL)', 'RBS(mg/dl)', 'Weight gain(Y/N)',\n",
    "       'hair growth(Y/N)', 'Skin darkening (Y/N)', 'Hair loss(Y/N)',\n",
    "       'Pimples(Y/N)', 'Fast food (Y/N)', 'Reg.Exercise(Y/N)',\n",
    "       'BP_Systolic(mmHg)', 'BP_Diastolic(mmHg)', 'Follicle No. (L)',\n",
    "       'Follicle No. (R)', 'Avg. F size (L) (mm)', 'Avg. F size (R) (mm)',\n",
    "       'Endometrium (mm)']\n",
    "\n",
    "sc = StandardScaler()\n",
    "for col in cols:\n",
    "    X_train[col] = sc.fit_transform(X_train[[col]])\n",
    "    X_test[col] = sc.transform(X_test[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8703703703703703\n",
      "F1-score: 0.8720481044424706\n",
      "Jaccard score: 0.6818181818181818\n",
      "AUC score: 0.8669275929549902\n",
      "Confusion matrix: \n",
      " [[64  9]\n",
      " [ 5 30]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90        73\n",
      "           1       0.77      0.86      0.81        35\n",
      "\n",
      "    accuracy                           0.87       108\n",
      "   macro avg       0.85      0.87      0.86       108\n",
      "weighted avg       0.88      0.87      0.87       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train,y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred, average='weighted')) \n",
    "print(\"Jaccard score:\", jaccard_score(y_test, y_pred))\n",
    "print(\"AUC score:\", roc_auc_score(y_test, y_pred))\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9351851851851852\n",
      "F1-score: 0.9337654006528178\n",
      "Jaccard score: 0.8055555555555556\n",
      "AUC score: 0.9074363992172212\n",
      "Confusion matrix: \n",
      " [[72  1]\n",
      " [ 6 29]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        73\n",
      "           1       0.97      0.83      0.89        35\n",
      "\n",
      "    accuracy                           0.94       108\n",
      "   macro avg       0.94      0.91      0.92       108\n",
      "weighted avg       0.94      0.94      0.93       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = LogisticRegression(random_state=42)\n",
    "dt.fit(X_train,y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred, average='weighted')) \n",
    "print(\"Jaccard score:\", jaccard_score(y_test, y_pred))\n",
    "print(\"AUC score:\", roc_auc_score(y_test, y_pred))\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9259259259259259\n",
      "F1-score: 0.9239156920077972\n",
      "Jaccard score: 0.7777777777777778\n",
      "AUC score: 0.8931506849315068\n",
      "Confusion matrix: \n",
      " [[72  1]\n",
      " [ 7 28]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95        73\n",
      "           1       0.97      0.80      0.88        35\n",
      "\n",
      "    accuracy                           0.93       108\n",
      "   macro avg       0.94      0.89      0.91       108\n",
      "weighted avg       0.93      0.93      0.92       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = SVC(random_state=42)\n",
    "dt.fit(X_train,y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred, average='weighted')) \n",
    "print(\"Jaccard score:\", jaccard_score(y_test, y_pred))\n",
    "print(\"AUC score:\", roc_auc_score(y_test, y_pred))\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 142, number of negative: 290\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1570\n",
      "[LightGBM] [Info] Number of data points in the train set: 432, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.328704 -> initscore=-0.714054\n",
      "[LightGBM] [Info] Start training from score -0.714054\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy: 0.9629629629629629\n",
      "F1-score: 0.962334455667789\n",
      "Jaccard score: 0.8857142857142857\n",
      "AUC score: 0.9428571428571428\n",
      "Confusion matrix: [[73  0]\n",
      " [ 4 31]]\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97        73\n",
      "           1       1.00      0.89      0.94        35\n",
      "\n",
      "    accuracy                           0.96       108\n",
      "   macro avg       0.97      0.94      0.96       108\n",
      "weighted avg       0.96      0.96      0.96       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = LGBMClassifier(random_state=42)\n",
    "dt.fit(X_train,y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred, average='weighted')) \n",
    "print(\"Jaccard score:\", jaccard_score(y_test, y_pred))\n",
    "print(\"AUC score:\", roc_auc_score(y_test, y_pred))\n",
    "print(\"Confusion matrix:\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9629629629629629\n",
      "F1-score: 0.9626685509038451\n",
      "Jaccard score: 0.8888888888888888\n",
      "AUC score: 0.9502935420743639\n",
      "Confusion matrix: \n",
      " [[72  1]\n",
      " [ 3 32]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97        73\n",
      "           1       0.97      0.91      0.94        35\n",
      "\n",
      "    accuracy                           0.96       108\n",
      "   macro avg       0.96      0.95      0.96       108\n",
      "weighted avg       0.96      0.96      0.96       108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = XGBClassifier(random_state=42)\n",
    "dt.fit(X_train,y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred, average='weighted')) \n",
    "print(\"Jaccard score:\", jaccard_score(y_test, y_pred))\n",
    "print(\"AUC score:\", roc_auc_score(y_test, y_pred))\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 142, number of negative: 290\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1723\n",
      "[LightGBM] [Info] Number of data points in the train set: 432, number of used features: 41\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.328704 -> initscore=-0.714054\n",
      "[LightGBM] [Info] Start training from score -0.714054\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "# Modellerin ve metriklerin isimleri\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'SVC': SVC(),\n",
    "    'DecisionTree': DecisionTreeClassifier(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    'LightGBM': LGBMClassifier()\n",
    "}\n",
    "\n",
    "metrics = ['accuracy', 'f1', 'jaccard', 'auc']\n",
    "\n",
    "results_list = []\n",
    "\n",
    "# Her modeli eÄŸit ve metrikleri hesapla\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    jaccard = jaccard_score(y_test, y_pred)\n",
    "    \n",
    "    # AUC score sadece binary sÄ±nÄ±flandÄ±rma modelleri iÃ§indir, bu nedenle kontrol yapalÄ±m\n",
    "    if isinstance(model, (LogisticRegression, SVC, DecisionTreeClassifier, XGBClassifier, LGBMClassifier)):\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "    else:\n",
    "        auc = None\n",
    "    \n",
    "    # Liste Ã¼zerinde tuple olarak sonuÃ§larÄ± ekleyin\n",
    "    results_list.append((model_name, accuracy, f1, jaccard, auc))\n",
    "\n",
    "# Listeyi kullanarak sonuÃ§larÄ± DataFrame'e Ã§evir\n",
    "results_df = pd.DataFrame(results_list, columns=['Model', 'Accuracy', 'F1 Score', 'Jaccard Score', 'AUC Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Jaccard Score</th>\n",
       "      <th>AUC Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.935185</td>\n",
       "      <td>0.892308</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.907436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.893151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.867515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.950294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.942857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Accuracy  F1 Score  Jaccard Score  AUC Score\n",
       "0  LogisticRegression  0.935185  0.892308       0.805556   0.907436\n",
       "1                 SVC  0.925926  0.875000       0.777778   0.893151\n",
       "2        DecisionTree  0.861111  0.805195       0.673913   0.867515\n",
       "3             XGBoost  0.962963  0.941176       0.888889   0.950294\n",
       "4            LightGBM  0.962963  0.939394       0.885714   0.942857"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "index =[\"non PCOS\", \"PCOS\"]\n",
    "columns=[\"non PCOS\",\"PCOS\"]\n",
    "cm = pd.DataFrame(confusion_matrix(y_test,y_pred), index=index, columns=columns)\n",
    "sns.heatmap(cm, annot=True, fmt='d', annot_kws={'size': 15, 'fontweight': 'semibold'})\n",
    "plt.xlabel(\"Predicted value\")\n",
    "plt.ylabel(\"Actual value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.title('ROC eÄŸrisi')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('DoÄŸru Pozitif OranÄ±')\n",
    "plt.xlabel('YanlÄ±ÅŸ Pozitif OranÄ±')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parameters = {'criterion':['gini','entropy'],'max_depth':[2,5,10,20,30,90],'random_state':[42,34,2]}\n",
    "grid = GridSearchCV(DecisionTreeClassifier(), parameters, cv=10)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "best_parameters=grid.best_params_\n",
    "\n",
    "print(\"en iyi parametreler: \\n\",best_parameters)\n",
    "\n",
    "grid_model = DecisionTreeClassifier(criterion=best_parameters[\"criterion\"],\n",
    "                               max_depth=best_parameters[\"max_depth\"])\n",
    "\n",
    "tuned_model = grid_model.fit(X_train, y_train)\n",
    "y_pred = tuned_model.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Modelleri ve hiperparametre uzayÄ±nÄ± tanÄ±mlayÄ±n\n",
    "models = {\n",
    "    'LogisticRegression': (LogisticRegression(), {'C': [0.001, 0.01, 0.1, 1, 10, 100]}),\n",
    "    'SVC': (SVC(), {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'kernel': ['linear', 'rbf']}),\n",
    "    'DecisionTree': (DecisionTreeClassifier(), {'max_depth': [None, 10, 20, 30, 40]}),\n",
    "    'XGBoost': (XGBClassifier(), {'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3], 'n_estimators': [50, 100, 200, 300]}),\n",
    "    'LightGBM': (LGBMClassifier(), {'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3], 'n_estimators': [50, 100, 200, 300]})\n",
    "}\n",
    "\n",
    "# Her model iÃ§in GridSearchCV uygula\n",
    "for model_name, (model, param_grid) in models.items():\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # En iyi hiperparametreleri ve doÄŸruluk skorunu yazdÄ±r\n",
    "    print(f\"Best parameters for {model_name}: {grid_search.best_params_}\")\n",
    "    print(f\"Best accuracy score for {model_name}: {grid_search.best_score_}\")\n",
    "\n",
    "    # Test seti Ã¼zerinde performansÄ± deÄŸerlendir\n",
    "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test accuracy score for {model_name}: {accuracy}\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
